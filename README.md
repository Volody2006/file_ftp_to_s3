# Архитектура сервиса
### Общая концепция
Сервис состоит из трех независимых компонентов.

Веб-приложение на FASTAPI, для создания FTP серверов, изменения их статуса и контроля за файлами и их статусами.
Планировщик СЕLERY BEAT. Запускает периодические задачи на поиск новых файлов и обработки зависших файлов.
Обработчик задач СЕLERY. Непосредственно выполняет периодические задания.
Именно он отвечает за параллельность процесса.
В случае необходимости поднимает дополнительные сервера с СЕLERY.

Эта архитектура позволяет максимально распараллеливать работу: проверка разных серверов может идти одновременно,
и обработка каждого файла также происходит в отдельном процессе.

Схема БД (PostgreSQL)
Нам понадобятся две основные таблицы: одна для хранения конфигурации серверов, другая — для отслеживания состояния файлов.
sftp_servers - Хранит данные для подключения к SFTP-серверам.
id (PK, Integer): Уникальный идентификатор сервера.
host (String): IP-адрес или доменное имя сервера.
port (Integer): Порт SFTP (обычно 22).
username (String): Имя пользователя.
credentials (String, Encrypted): Зашифрованные креды (пароль или ключ). Никогда не храните пароли в открытом виде!
directory (String): Каталог на сервере для мониторинга.
is_active (Boolean): Флаг для временного включения/отключения мониторинга сервера через UI.

imported_files - Журнал всех обнаруженных и обработанных файлов. Это "сердце" системы, обеспечивающее идемпотентность и отслеживание.
id (PK, Integer): Уникальный идентификатор файла.
server_id (FK -> sftp_servers.id): Ссылка на сервер, откуда пришел файл.
filename (String): Имя файла.
filesize (BigInteger): Размер файла в байтах.
file_hash (String, nullable): Хеш файла (например, SHA256) для дополнительной проверки целостности. Может вычисляться во время скачивания.
status (Enum): Статус обработки файла. Ключевое поле для надежности. (Обнаружен, скачивается, скачан, загружается на S3 и так далее)
error_message (Text, nullable): Текст ошибки, если статус FAILED.
created_at (DateTime): Время обнаружения файла.
updated_at (DateTime): Время последнего изменения статуса.
Constraint: UNIQUE(server_id, filename) — критически важный индекс, который на уровне БД защищает от повторного добавления одного и того же файла с одного сервера.

### Модули приложения
webapp: Небольшое веб-приложение для управления серверами и просмотра статусов файлов.
Оно напрямую работает с БД через SQLAlchemy.

celery_worker.py: Основной модуль с логикой фоновых задач.
Инициализация и конфигурация Celery, включая настройку Celery Beat для периодического запуска.

connectors.py: Модули для взаимодействия с внешними системами, чтобы инкапсулировать логику подключения. (AmqpPublisher, MinioClient).
В реальном проекте каждый класс вынес бы в отдельные файлы, но здесь в одном для простоты.

### Алгоритм работы части, отвечающей за скачивание
Планировщик (Celery Beat):

С заданной периодичностью (например, раз в 30 сек.) запускает "мета-задачу" discover_all_servers.
Эта мета-задача запрашивает из БД все серверы с флагом is_active=True.
Для каждого активного сервера она запускает отдельную задачу discover_files_on_server,
передавая ей server_id.

Функция discover_files_on_server(server_id) (Celery Task):
Принимает server_id.
Извлекает из БД креды и путь к каталогу для этого сервера.
Подключается к SFTP. В случае неудачи, задача завершается и будет перезапущена Celery позже.

Обнаруживает новые файлы и запускает для каждого задачу скачивания.
Для каждого нового файла:
Запускает новые задачи download_file.

download_file - Скачивает файл с SFTP в общую временную директорию. Запускает задачу upload_to_minio.
upload_to_minio - Загружает скачанный файл из временной директории в MinIO и запускает задачу notify_and_cleanup
notify_and_cleanup = Отправляет уведомление и удаляет временный файл.

reconcile_stuck_files - Находит файлы, застрявшие на промежуточных этапах, и перезапускает их обработку.
Запускается каждые 15 минут.


### Подводные камни и внештатные ситуации
Файл еще не до конца записан: Внешнее приложение может еще записывать файл в тот момент, когда наш сервис его обнаружит.
Решение: Лучшая практика — договориться с владельцами внешних приложений об атомарности операции.
Например, они пишут файл с расширением .tmp, а по завершении записи переименовывают его в нужный формат.
Наш сервис должен игнорировать файлы .tmp. Если это невозможно, можно проверять размер и время модификации файла:
если они не меняются в течение двух проверок подряд, считать файл готовым. Но это усложняет логику (не реализовано).

Сбой воркера в середине процесса: Воркер может упасть в любой момент.
Решение: Статусная модель в БД. Если воркер упал, файл останется в предыдущем статусе.
Есть "задача-санитара" (тоже Celery Beat), которая периодически ищет файлы, "зависшие" в промежуточных статусах (например, DOWNLOADING дольше часа),
и пробует запустить задачу еще раз.

Проблемы с сетью: Потеря связи с SFTP, MinIO или RabbitMQ.
Решение: Встроенные механизмы retry в Celery. Задачу process_file нужно настроить так,
чтобы она повторялась несколько раз с экспоненциальной задержкой в случае любого исключения (например, IOError, ConnectionError).
Если после всех попыток не удалось, статус меняется на FAILED с записью ошибки.

"Гонка" между обнаружителями: Два воркера одновременно проверяют один и тот же сервер.
Решение: UNIQUE constraint в БД. Это самый надежный и простой способ.

Большие файлы и память/диск воркера: Файл в несколько гигабайт может исчерпать память или место на диске воркера.
Решение: Использовать потоковые операции для чтения/записи и временные файлы (tempfile в Python).
Убедиться, что у воркеров достаточно дискового пространства для временного хранения хотя бы нескольких самых
больших файлов одновременно.


### Запуск и тестирование.
Для развертывания локально установите докер.
Запустите приложение в докере. 

